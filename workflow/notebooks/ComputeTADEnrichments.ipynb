{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import binom, hypergeom\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from bioinf_common.tools import multipletests_nan\n",
    "\n",
    "from tad_helper_functions import get_tad_lengths, EmptyTAD, TADTooSmall, OverlappingTADs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_fname = snakemake.input.db_fname\n",
    "tads_fname = snakemake.input.tads_fname\n",
    "info_fname = snakemake.input.info_fname\n",
    "\n",
    "source = snakemake.wildcards.source\n",
    "filter_type = snakemake.wildcards.filter\n",
    "tad_borders = snakemake.config['tad_borders']\n",
    "allow_snp_multiplicity_in_enrichment = snakemake.config['parameters']['allow_snp_multiplicity_in_enrichment']\n",
    "enrichment_distribution = snakemake.config['parameters']['enrichment_distribution']\n",
    "enrichment_null_model = snakemake.config['parameters']['enrichment_null_model']\n",
    "\n",
    "fname_out = snakemake.output.fname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(db_fname)\n",
    "display(df.head())\n",
    "\n",
    "disease_cancer_map = df.set_index('diseaseId').to_dict()['is_cancer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = pd.read_csv(info_fname, index_col=1)\n",
    "genome_assembly = df_info.loc[source, 'genome_assembly']\n",
    "genome_assembly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get TAD stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_length = {\n",
    "    'hg19': 2_991_688_216,  # https://www.ncbi.nlm.nih.gov/grc/human/data?asm=GRCh37.p13\n",
    "    'hg38': 3_092_480_053,  # https://www.ncbi.nlm.nih.gov/grc/human/data?asm=GRCh38.p11\n",
    "}[genome_assembly]\n",
    "\n",
    "df_tads = pd.read_csv(tads_fname)\n",
    "df_tads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tads['prev_tad_stop'] = df_tads.tad_stop.shift(1)\n",
    "df_tads['next_tad_start'] = df_tads.tad_start.shift(-1)\n",
    "df_tads['prev_tad_chr'] = df_tads.chrname.shift(1)\n",
    "df_tads['next_tad_chr'] = df_tads.chrname.shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tad_statistics = collections.defaultdict(dict)\n",
    "\n",
    "for border_name, border_range in tqdm(tad_borders.items()):\n",
    "    tad_len = 0\n",
    "    border_len = 0\n",
    "    chrom_lens = collections.defaultdict(list)\n",
    "    for row in df_tads.itertuples():\n",
    "        try:\n",
    "            b1_range, tad_range, b2_range = get_tad_lengths(row, border_range)\n",
    "        except (EmptyTAD, TADTooSmall, OverlappingTADs):\n",
    "            continue\n",
    "\n",
    "        tad_len += tad_range.stop - tad_range.start\n",
    "        border_len += \\\n",
    "            (b1_range.stop - b1_range.start) \\\n",
    "            + (b2_range.stop - b2_range.start)\n",
    "\n",
    "        chrom_lens[row.chrname].append(row.tad_stop)\n",
    "\n",
    "    outside_len = genome_length - tad_len - border_len\n",
    "\n",
    "    tad_statistics[border_name]['chrom'] = genome_length\n",
    "    tad_statistics[border_name]['tad'] = tad_len\n",
    "    tad_statistics[border_name]['border'] = border_len\n",
    "    tad_statistics[border_name]['outside'] = outside_len\n",
    "\n",
    "tad_statistics = dict(tad_statistics)\n",
    "tad_statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute enrichments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_column = f'filter_{filter_type}_{genome_assembly}'\n",
    "filter_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter_sub = df[df[filter_column]]\n",
    "print(df.shape, df_filter_sub.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enr_result = []\n",
    "for disease, group in tqdm(df_filter_sub.groupby('diseaseId'), total=df_filter_sub['diseaseId'].nunique()):\n",
    "    for border_name in tad_borders.keys():\n",
    "        # get TAD-related statistics\n",
    "        if allow_snp_multiplicity_in_enrichment:\n",
    "            tads = group[border_name].tolist()\n",
    "            \n",
    "            snp_counts = {\n",
    "                'total': df_filter_sub['snpId'].shape[0],\n",
    "                'tad': df_filter_sub.loc[df_filter_sub[border_name] == 'tad', 'snpId'].shape[0],\n",
    "                'border': df_filter_sub.loc[df_filter_sub[border_name] == 'border', 'snpId'].shape[0],\n",
    "                'outside': df_filter_sub.loc[df_filter_sub[border_name] == 'outside', 'snpId'].shape[0]\n",
    "            }\n",
    "        else:\n",
    "            tads = group[['snpId', border_name]].drop_duplicates(subset='snpId')[border_name]\n",
    "            \n",
    "            snp_counts = {\n",
    "                'total': df_filter_sub['snpId'].drop_duplicates().shape[0],\n",
    "                'tad': df_filter_sub.loc[df_filter_sub[border_name] == 'tad', 'snpId'].drop_duplicates().shape[0],\n",
    "                'border': df_filter_sub.loc[df_filter_sub[border_name] == 'border', 'snpId'].drop_duplicates().shape[0],\n",
    "                'outside': df_filter_sub.loc[df_filter_sub[border_name] == 'outside', 'snpId'].drop_duplicates().shape[0]\n",
    "            }\n",
    "        \n",
    "        N = len(tads)\n",
    "        counts = collections.Counter(tads)\n",
    "        \n",
    "        # compute enrichment\n",
    "        if counts['border'] == 0:\n",
    "            cdf_tad = np.nan\n",
    "            cdf_border = np.nan\n",
    "            cdf_outside = np.nan\n",
    "        else:\n",
    "            if enrichment_null_model == 'base_sample':\n",
    "                # get overall lengths\n",
    "                cur_cl = tad_statistics[border_name]['chrom']\n",
    "                cur_tl = tad_statistics[border_name]['tad']\n",
    "                cur_bl = tad_statistics[border_name]['border']\n",
    "                cur_nl = tad_statistics[border_name]['outside']\n",
    "                \n",
    "                if enrichment_distribution == 'binom':\n",
    "                    cdf_tad = binom.cdf(counts['tad'], N, cur_tl/cur_cl)\n",
    "                    cdf_border = binom.cdf(counts['border'], N, cur_bl/cur_cl)\n",
    "                    cdf_outside = binom.cdf(counts['outside'], N, cur_nl/cur_cl)\n",
    "                elif enrichment_distribution == 'hypergeom':\n",
    "                    cdf_tad = hypergeom.cdf(counts['tad'], cur_cl, N, cur_tl)\n",
    "                    cdf_border = hypergeom.cdf(counts['border'], cur_cl, N, cur_bl)\n",
    "                    cdf_outside = hypergeom.cdf(counts['outside'], cur_cl, N, cur_nl)\n",
    "            elif enrichment_null_model == 'snp_sample':\n",
    "                if enrichment_distribution == 'binom':\n",
    "                    cdf_tad = binom.cdf(counts['tad'], N, snp_counts['tad']/snp_counts['total'])\n",
    "                    cdf_border = binom.cdf(counts['border'], N, snp_counts['border']/snp_counts['total'])\n",
    "                    cdf_outside = binom.cdf(counts['outside'], N, snp_counts['outside']/snp_counts['total'])\n",
    "                elif enrichment_distribution == 'hypergeom':\n",
    "                    cdf_tad = hypergeom.cdf(counts['tad'], snp_counts['total'], N, snp_counts['tad'])\n",
    "                    cdf_border = hypergeom.cdf(counts['border'], snp_counts['total'], N, snp_counts['border'])\n",
    "                    cdf_outside = hypergeom.cdf(counts['outside'], snp_counts['total'], N, snp_counts['outside'])\n",
    "        \n",
    "        enr_result.append({\n",
    "            'diseaseId': disease,\n",
    "            '#snp': N,\n",
    "            '#border_snp': counts['border'],\n",
    "            'pval_tad': 1 - cdf_tad,\n",
    "            'pval_border': 1 - cdf_border,\n",
    "            'pval_outside': 1 - cdf_outside,\n",
    "            'TAD_type': border_name\n",
    "        })\n",
    "df_enr = pd.DataFrame(enr_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple-testing correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enr['is_cancer'] = df_enr['diseaseId'].apply(lambda x: disease_cancer_map[x])\n",
    "df_enr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enr_tmp = df_enr.copy()\n",
    "df_enr_tmp['is_cancer'] = df_enr_tmp['diseaseId'].apply(lambda x: disease_cancer_map[x])\n",
    "df_enr_corr = df_enr_tmp.groupby(['TAD_type', 'is_cancer'])[['pval_border', 'pval_tad', 'pval_outside']].transform(multipletests_nan)\n",
    "\n",
    "df_enr['pval_border__notcorrected'] = df_enr['pval_border']\n",
    "df_enr['pval_outside__notcorrected'] = df_enr['pval_outside']\n",
    "df_enr['pval_tad__notcorrected'] = df_enr['pval_tad']\n",
    "\n",
    "df_enr['pval_border'] = df_enr_corr['pval_border']\n",
    "df_enr['pval_outside'] = df_enr_corr['pval_outside']\n",
    "df_enr['pval_tad'] = df_enr_corr['pval_tad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enr.to_csv(fname_out, index=False)\n",
    "df_enr.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
