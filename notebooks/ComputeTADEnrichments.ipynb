{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import binom, hypergeom\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from bioinf_common.tools import multipletests_nan\n",
    "\n",
    "from tad_helper_functions import get_tad_lengths, EmptyTAD, OverlappingTADS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_fname = snakemake.input.db_fname\n",
    "tads_fname = snakemake.input.tads_fname\n",
    "info_fname = snakemake.input.info_fname\n",
    "\n",
    "source = snakemake.wildcards.source\n",
    "filter_type = snakemake.wildcards.filter\n",
    "allow_snp_multiplicity_in_enrichment = snakemake.config['parameters']['allow_snp_multiplicity_in_enrichment']\n",
    "enrichment_distribution = snakemake.config['parameters']['enrichment_distribution']\n",
    "enrichment_null_model = snakemake.config['parameters']['enrichment_null_model']\n",
    "\n",
    "fname_out = snakemake.output.fname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(db_fname)\n",
    "display(df.head())\n",
    "\n",
    "disease_cancer_map = df.set_index('diseaseId').to_dict()['is_cancer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAD_border_types = df.filter(like='TAD_').columns.tolist()\n",
    "TAD_border_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = pd.read_csv(info_fname, index_col=1)\n",
    "genome_assembly = df_info.loc[source, 'genome_assembly']\n",
    "genome_assembly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get TAD stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_length = {\n",
    "    'hg19': 2_991_688_216,  # https://www.ncbi.nlm.nih.gov/grc/human/data?asm=GRCh37.p13\n",
    "    'hg38': 3_092_480_053,  # https://www.ncbi.nlm.nih.gov/grc/human/data?asm=GRCh38.p11\n",
    "}[genome_assembly]\n",
    "\n",
    "df_tads = pd.read_csv(tads_fname)\n",
    "df_tads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tads['prev_tad_stop'] = df_tads.tad_stop.shift(1)\n",
    "df_tads['next_tad_start'] = df_tads.tad_start.shift(-1)\n",
    "df_tads['prev_tad_chr'] = df_tads.chrname.shift(1)\n",
    "df_tads['next_tad_chr'] = df_tads.chrname.shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tad_statistics = collections.defaultdict(dict)\n",
    "for tad_type in tqdm(TAD_border_types):\n",
    "    type_ = tad_type[4:]  # remove TAD_\n",
    "\n",
    "    tad_len = 0\n",
    "    boundary_len = 0\n",
    "    chrom_lens = collections.defaultdict(list)\n",
    "    for row in df_tads.itertuples():\n",
    "        try:\n",
    "            b1_range, tad_range, b2_range = get_tad_lengths(row, type_)\n",
    "        except (EmptyTAD, OverlappingTADS):\n",
    "            continue\n",
    "\n",
    "        tad_len += tad_range.stop - tad_range.start\n",
    "        boundary_len += \\\n",
    "            (b1_range.stop - b1_range.start) \\\n",
    "            + (b2_range.stop - b2_range.start)\n",
    "\n",
    "        chrom_lens[row.chrname].append(row.tad_stop)\n",
    "\n",
    "    none_len = genome_length - tad_len - boundary_len\n",
    "\n",
    "    tad_statistics[type_]['chrom'] = genome_length\n",
    "    tad_statistics[type_]['tad'] = tad_len\n",
    "    tad_statistics[type_]['boundary'] = boundary_len\n",
    "    tad_statistics[type_]['none'] = none_len\n",
    "tad_statistics = dict(tad_statistics)\n",
    "    \n",
    "tad_statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute enrichments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_column = f'filter_{filter_type}_{genome_assembly}'\n",
    "filter_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter_sub = df[df[filter_column]]\n",
    "print(df.shape, df_filter_sub.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enr_result = []\n",
    "for disease, group in tqdm(df_filter_sub.groupby('diseaseId'), total=df_filter_sub['diseaseId'].nunique()):\n",
    "    for tad_type in TAD_border_types:\n",
    "        # get TAD-related statistics\n",
    "        if allow_snp_multiplicity_in_enrichment:\n",
    "            tads = group[tad_type].tolist()\n",
    "            \n",
    "            snp_counts = {\n",
    "                'total': df_filter_sub['snpId'].shape[0],\n",
    "                'tad': df_filter_sub.loc[df_filter_sub[tad_type] == 'tad', 'snpId'].shape[0],\n",
    "                'boundary': df_filter_sub.loc[df_filter_sub[tad_type] == 'boundary', 'snpId'].shape[0],\n",
    "                'none': df_filter_sub.loc[df_filter_sub[tad_type] == 'outside', 'snpId'].shape[0]\n",
    "            }\n",
    "        else:\n",
    "            tads = group[['snpId', tad_type]].drop_duplicates(subset='snpId')[tad_type]\n",
    "            \n",
    "            snp_counts = {\n",
    "                'total': df_filter_sub['snpId'].drop_duplicates().shape[0],\n",
    "                'tad': df_filter_sub.loc[df_filter_sub[tad_type] == 'tad', 'snpId'].drop_duplicates().shape[0],\n",
    "                'boundary': df_filter_sub.loc[df_filter_sub[tad_type] == 'boundary', 'snpId'].drop_duplicates().shape[0],\n",
    "                'none': df_filter_sub.loc[df_filter_sub[tad_type] == 'outside', 'snpId'].drop_duplicates().shape[0]\n",
    "            }\n",
    "        \n",
    "        N = len(tads)\n",
    "        counts = collections.Counter(tads)\n",
    "        \n",
    "        # get overall lengths\n",
    "        type_ = tad_type[4:]  # remove TAD_\n",
    "        cur_cl = tad_statistics[type_]['chrom']\n",
    "        cur_tl = tad_statistics[type_]['tad']\n",
    "        cur_bl = tad_statistics[type_]['boundary']\n",
    "        cur_nl = tad_statistics[type_]['none']\n",
    "        \n",
    "        # compute enrichment\n",
    "        if counts['boundary'] == 0:\n",
    "            cdf_tad = np.nan\n",
    "            cdf_boundary = np.nan\n",
    "            cdf_none = np.nan\n",
    "        else:\n",
    "            if enrichment_null_model == 'base_sample':\n",
    "                if enrichment_distribution == 'binom':\n",
    "                    cdf_tad = binom.cdf(counts['tad'], N, cur_tl/cur_cl)\n",
    "                    cdf_boundary = binom.cdf(counts['boundary'], N, cur_bl/cur_cl)\n",
    "                    cdf_none = binom.cdf(counts['nan'], N, cur_nl/cur_cl)\n",
    "                elif enrichment_distribution == 'hypergeom':\n",
    "                    cdf_tad = hypergeom.cdf(counts['tad'], cur_cl, N, cur_tl)\n",
    "                    cdf_boundary = hypergeom.cdf(counts['boundary'], cur_cl, N, cur_bl)\n",
    "                    cdf_none = hypergeom.cdf(counts['nan'], cur_cl, N, cur_nl)\n",
    "            elif enrichment_null_model == 'snp_sample':\n",
    "                if enrichment_distribution == 'binom':\n",
    "                    cdf_tad = binom.cdf(counts['tad'], N, snp_counts['tad']/snp_counts['total'])\n",
    "                    cdf_boundary = binom.cdf(counts['boundary'], N, snp_counts['boundary']/snp_counts['total'])\n",
    "                    cdf_none = binom.cdf(counts['nan'], N, snp_counts['none']/snp_counts['total'])\n",
    "                elif enrichment_distribution == 'hypergeom':\n",
    "                    cdf_tad = hypergeom.cdf(counts['tad'], snp_counts['total'], N, snp_counts['tad'])\n",
    "                    cdf_boundary = hypergeom.cdf(counts['boundary'], snp_counts['total'], N, snp_counts['boundary'])\n",
    "                    cdf_none = hypergeom.cdf(counts['nan'], snp_counts['total'], N, snp_counts['none'])\n",
    "        \n",
    "        enr_result.append({\n",
    "            'diseaseId': disease,\n",
    "            '#snp': N,\n",
    "            '#border_snp': counts['boundary'],\n",
    "            'pval_tad': 1 - cdf_tad,\n",
    "            'pval_boundary': 1 - cdf_boundary,\n",
    "            'pval_none': 1 - cdf_none,\n",
    "            'TAD_type': type_\n",
    "        })\n",
    "df_enr = pd.DataFrame(enr_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple-testing correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enr['is_cancer'] = df_enr['diseaseId'].apply(lambda x: disease_cancer_map[x])\n",
    "df_enr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enr_tmp = df_enr.copy()\n",
    "df_enr_tmp['is_cancer'] = df_enr_tmp['diseaseId'].apply(lambda x: disease_cancer_map[x])\n",
    "df_enr_corr = df_enr_tmp.groupby(['TAD_type', 'is_cancer'])[['pval_boundary', 'pval_tad', 'pval_none']].transform(multipletests_nan)\n",
    "\n",
    "df_enr['pval_boundary__notcorrected'] = df_enr['pval_boundary']\n",
    "df_enr['pval_none__notcorrected'] = df_enr['pval_none']\n",
    "df_enr['pval_tad__notcorrected'] = df_enr['pval_tad']\n",
    "\n",
    "df_enr['pval_boundary'] = df_enr_corr['pval_boundary']\n",
    "df_enr['pval_none'] = df_enr_corr['pval_none']\n",
    "df_enr['pval_tad'] = df_enr_corr['pval_tad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enr.to_csv(fname_out, index=False)\n",
    "df_enr.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
