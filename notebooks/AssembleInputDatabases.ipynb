{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext ipy_pdcache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import onto2nx\n",
    "import pybiomart\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from gene_map import GeneMapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "disgenet_fname = snakemake.input.disgenet_fname\n",
    "gwascatalog_fname = snakemake.input.gwascatalog_fname\n",
    "efo_fname = snakemake.input.efo_fname\n",
    "so_fname = snakemake.input.so_fname\n",
    "\n",
    "db_out_fname = snakemake.output.db_fname\n",
    "raw_veps_fname = snakemake.output.raw_veps\n",
    "\n",
    "gwas_gene_source = snakemake.config['parameters']['associated_gene_source']\n",
    "annotation_sources = snakemake.config['annotation_sources']\n",
    "snp_filters = snakemake.config['snp_filters']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load DisGeNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_disgenet = pd.read_table(\n",
    "    disgenet_fname,\n",
    "    usecols=['snpId', 'diseaseId','diseaseName', 'source'])\n",
    "\n",
    "df_disgenet['snp_source'] = 'disgenet'\n",
    "df_disgenet['diseaseIdType'] = 'UMLS_CUI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_disgenet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load GWAS catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gwascat = pd.read_table(gwascatalog_fname, low_memory=False)\n",
    "\n",
    "#df_gwascat = df_gwascat[['SNP_ID_CURRENT', 'MAPPED_TRAIT_URI', 'MAPPED_TRAIT']]\n",
    "df_gwascat.dropna(subset=['SNP_ID_CURRENT', 'MAPPED_TRAIT_URI', 'MAPPED_TRAIT'], inplace=True)\n",
    "df_gwascat.rename(columns={\n",
    "    'SNP_ID_CURRENT': 'snpId', 'MAPPED_TRAIT_URI': 'diseaseId', 'MAPPED_TRAIT': 'diseaseName'\n",
    "}, inplace=True)\n",
    "\n",
    "df_gwascat['snpId'] = df_gwascat['snpId'].apply(lambda x: f'rs{x}')\n",
    "df_gwascat['snp_source'] = 'gwas_catalog'\n",
    "\n",
    "df_gwascat['diseaseId'] = df_gwascat['diseaseId'].str.split(',')\n",
    "df_gwascat = df_gwascat.explode('diseaseId')\n",
    "\n",
    "df_gwascat['diseaseId'] = df_gwascat['diseaseId'].apply(lambda x: x.split('/')[-1])\n",
    "df_gwascat['diseaseIdType'] = df_gwascat['diseaseId'].apply(lambda x: x.split('_')[0])\n",
    "\n",
    "# convert BETA to odds ratio\n",
    "df_gwascat['odds_ratio'] = df_gwascat['OR or BETA'].apply(lambda x: np.exp(x) if x < 1 else x)\n",
    "\n",
    "df_gwascat.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infer associated gene(s)\n",
    "\n",
    "Possible columns:\n",
    "* REPORTED GENE(S): gene reported by author\n",
    "* MAPPED GENE: Gene(s) mapped to the strongest SNP (if SNP is intergenic uses upstream and downstream genes)\n",
    "* SNP_GENE_IDS: Entrez Gene ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gwascat[['REPORTED GENE(S)', 'MAPPED_GENE', 'SNP_GENE_IDS']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gwas_gene_source == 'reported':\n",
    "    # are gene names, must be mapped to ENTREZ\n",
    "    raw_genes = df_gwascat['REPORTED GENE(S)'].str.split(', ').tolist()\n",
    "    \n",
    "    gene_blacklist = {'intergenic', 'NR'}\n",
    "    cur_genes = [g for gs in raw_genes if not isinstance(gs, float) for g in gs if g not in gene_blacklist]  # isinstance(gs,float) -> gs==np.nan\n",
    "    \n",
    "    gm = GeneMapper()\n",
    "    df_map = gm.query(id_list=cur_genes, source_id_type='Gene_Name', target_id_type='GeneID')\n",
    "    name2id = df_map.set_index('ID_from').to_dict()['ID_to']\n",
    "    \n",
    "    entrez_genes = [None \n",
    "                    if isinstance(gs, float) \n",
    "                    else [name2id[g] for g in gs if g in name2id]\n",
    "                    for gs in raw_genes]\n",
    "elif gwas_gene_source == 'mapped':\n",
    "    # are already ENTREZ IDs\n",
    "    raw_genes = df_gwascat['SNP_GENE_IDS'].str.split(', ').tolist()\n",
    "    entrez_genes = [None if isinstance(gs, float) else gs for gs in raw_genes]\n",
    "else:\n",
    "    raise RuntimeError(f'Invalid gene source: \"{gwas_gene_source}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gwascat['associated_genes'] = [None if gs is None else ','.join(gs) for gs in entrez_genes]\n",
    "df_gwascat[['REPORTED GENE(S)', 'MAPPED_GENE', 'SNP_GENE_IDS', 'associated_genes']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gwascat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gwascat = df_gwascat[['diseaseId', 'snpId', 'snp_source', 'diseaseIdType', 'odds_ratio', 'associated_genes']]\n",
    "df_gwascat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_gwascat])  #df_disgenet, \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load required ontologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "efo_graph = onto2nx.parse_owl(efo_fname)\n",
    "efo_graph.name = 'efo'\n",
    "print(nx.info(efo_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "so_graph = onto2nx.parse_owl(so_fname)\n",
    "so_graph.name = 'so'\n",
    "print(nx.info(so_graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efo_label_map = {idx: data['label'] for idx, data in efo_graph.nodes(data=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diseaseLabel'] = df['diseaseId'].map(efo_label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cancer classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_all = list(efo_graph.nodes())\n",
    "\n",
    "# find all disease-nodes\n",
    "nodes_disease = list(nx.ancestors(efo_graph, 'EFO_0000408')) + ['EFO_0000408']  # disease subtree (vs traits, ...)\n",
    "\n",
    "# find all cancer diseases\n",
    "nodes_cancer = list(nx.ancestors(efo_graph, 'EFO_0000311')) + ['EFO_0000311']  # cancer subtree\n",
    "\n",
    "# assert nodes_cancer <= nodes_disease\n",
    "# assert nodes_disease <= nodes_all  # ???\n",
    "print(f'#cancer/#disease/#all: {len(nodes_cancer)}/{len(nodes_disease)}/{len(nodes_all)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = []\n",
    "for disease in tqdm(df['diseaseId'].unique()):\n",
    "    if disease in nodes_disease:\n",
    "        tmp.append({'diseaseId': disease, 'is_cancer': disease in nodes_cancer})\n",
    "    else:\n",
    "        tmp.append({'diseaseId': disease, 'is_cancer': np.nan})\n",
    "    \n",
    "df_iscancer = pd.DataFrame(tmp)\n",
    "df_iscancer.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNP annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve VEP annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variant consequence ontology: http://www.sequenceontology.org/browser/current_release\n",
    "\n",
    "Description of variant types: https://www.ensembl.org/info/genome/variation/prediction/predicted_data.html\n",
    "\n",
    "Raw data: ftp://ftp.ensembl.org/pub/release-98/variation/vep/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snps = df['snpId'].unique().tolist()\n",
    "print(f'Retrieving annotations for {len(snps)} SNPs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%pdcache df_anno_raw $raw_veps_fname\n",
    "\n",
    "df_list = []\n",
    "for genome_assembly, annotation_url in annotation_sources.items():\n",
    "    if os.path.isfile(annotation_url):\n",
    "        print('Using local SNP annotations')\n",
    "        tmp = pd.read_csv(annotation_url, index_col=0)\n",
    "    else:\n",
    "        print('Retrieving SNP annotations from Ensembl')\n",
    "\n",
    "        tmp = None\n",
    "        while tmp is None:\n",
    "            try:\n",
    "                server = pybiomart.Server(host=annotation_url)\n",
    "                dataset = server.marts['ENSEMBL_MART_SNP'].datasets['hsapiens_snp']\n",
    "\n",
    "                tmp = dataset.query(\n",
    "                    attributes=['refsnp_id', 'chr_name', 'chrom_start', 'consequence_type_tv', 'ensembl_transcript_stable_id'],\n",
    "                    filters={'snp_filter': snps},\n",
    "                    use_attr_names=True)\n",
    "            except requests.HTTPError:\n",
    "                # retry if network error occurred\n",
    "                print('Next try...')\n",
    "                time.sleep(10)\n",
    "                \n",
    "    tmp['genome_assembly'] = genome_assembly\n",
    "    df_list.append(tmp)\n",
    "    \n",
    "df_anno_raw = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anno_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert annotations to usable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anno = df_anno_raw.copy()\n",
    "\n",
    "# processing preparations\n",
    "df_anno['chr_name'] = df_anno['chr_name'].astype(str)\n",
    "\n",
    "# remove haplotypes (e.g. CHR_HSCHR6_MHC_COX_CTG1)\n",
    "df_anno = df_anno[~df_anno['chr_name'].str.contains('_')]\n",
    "\n",
    "# mark empty consequence as 'intergenic' (NaN in dataframe shows up as intergenic in VEP web-interface)\n",
    "df_anno.loc[df_anno['consequence_type_tv'].isna(), 'consequence_type_tv'] = 'intergenic_variant'\n",
    "\n",
    "# select most frequent annotations (TODO: handle multiple maxima)\n",
    "tmp  = []\n",
    "for (snp, genome_assembly), group in tqdm(df_anno.groupby(['refsnp_id', 'genome_assembly'])):\n",
    "    top_vep = group['consequence_type_tv'].value_counts().idxmax()\n",
    "    match = group[group['consequence_type_tv'] == top_vep].iloc[0]\n",
    "    tmp.append(match)\n",
    "df_anno = pd.DataFrame(tmp)\n",
    "\n",
    "# set column names\n",
    "df_anno.drop('ensembl_transcript_stable_id', axis=1, inplace=True)\n",
    "\n",
    "df_anno.rename(\n",
    "    columns={\n",
    "        'refsnp_id': 'snpId', 'consequence_type_tv': 'variant_type',\n",
    "        'chr_name': 'chromosome', 'chrom_start': 'position'\n",
    "    }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anno.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group variant types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read sequence ontology (SO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exon_subgraph = list(nx.ancestors(so_graph, 'SO_0001791')) + ['SO_0001791']\n",
    "intron_subgraph = list(nx.ancestors(so_graph, 'SO_0001627')) + ['SO_0001627']\n",
    "intergenic_subgraph = list(nx.ancestors(so_graph, 'SO_0001628')) + ['SO_0001628']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find ontology labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "so_label_map = {data['label']: idx for idx, data in so_graph.nodes(data=True)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_vep(vep):\n",
    "    special_cases = {\n",
    "        'NMD_transcript_variant': 'exonic',\n",
    "        'mature_miRNA_variant': 'exonic',\n",
    "        'splice_region_variant': 'exonic',  # can be either exon or intron\n",
    "        'non_coding_transcript_variant': 'intronic'\n",
    "    }\n",
    "    \n",
    "    vep_id = so_label_map[vep]\n",
    "    if vep_id in exon_subgraph:\n",
    "        assert vep_id not in intron_subgraph and vep_id not in intergenic_subgraph, vep\n",
    "        return 'exonic'\n",
    "    elif vep_id in intron_subgraph:\n",
    "        assert vep_id not in exon_subgraph and vep_id not in intergenic_subgraph, vep\n",
    "        return 'intronic'\n",
    "    elif vep_id in intergenic_subgraph:\n",
    "        assert vep_id not in intron_subgraph and vep_id not in exon_subgraph, vep\n",
    "        return 'intergenic'\n",
    "    else:\n",
    "        return special_cases.get(vep, 'ambiguous')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anno['variant_group'] = df_anno['variant_type'].apply(classify_vep)\n",
    "df_anno['variant_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anno.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert that all SNPs have been annotated (TODO: make this rigorous)\n",
    "#assert set(df_anno['snpId'].tolist()) == set(snps), set(snps) - set(df_anno['snpId'].tolist())\n",
    "assert df_anno is not None\n",
    "assert df_anno.shape[0] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert that all variant types have been grouped\n",
    "assert df_anno['variant_group'].isna().sum() == 0, df_anno[df_anno.variant_group.isna()].drop_duplicates('variant_type')['variant_type'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert that variant type groups are reasonable\n",
    "#assert set(df_anno['variant_group']) <= {'exonic', 'intronic', 'intergenic', 'ambiguous'}, df_anno['variant_group'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistics\n",
    "print('#SNPs in database:', df['snpId'].nunique(), f'({len(snps)})')\n",
    "print('#annotated SNPs:', df_anno['snpId'].nunique())\n",
    "print('#intersection:', len(set(df['snpId'].tolist()) & set(df_anno['snpId'].tolist())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_agg(x):\n",
    "    assert len(x) <= 1\n",
    "    return x\n",
    "\n",
    "df_anno_trans = pd.pivot_table(\n",
    "    df_anno,\n",
    "    values=['chromosome', 'position', 'variant_type', 'variant_group'],\n",
    "    index=['snpId'],\n",
    "    columns=['genome_assembly'],\n",
    "    aggfunc=dummy_agg\n",
    ").reset_index()\n",
    "\n",
    "df_anno_trans.columns = ['_'.join(col).rstrip('_') for col in df_anno_trans.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anno_trans.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial aggregation\n",
    "df_final = df.copy()\n",
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cancer-classification\n",
    "df_final = df_final.merge(df_iscancer, on='diseaseId')\n",
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNP annotation\n",
    "df_final = df_final.merge(df_anno_trans, how='left')\n",
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep diseases (and not e.g. traits)\n",
    "df_final.dropna(subset=['is_cancer'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variant type filters (only add marker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filter_name, filter_query in snp_filters.items():\n",
    "    for genome_assembly in annotation_sources.keys():\n",
    "        idx = f'filter_{filter_name}_{genome_assembly}'\n",
    "\n",
    "        df_final[idx] = False\n",
    "        if filter_query is None:\n",
    "            df_final[idx] = True\n",
    "        else:\n",
    "            match = df_final.query(filter_query.format(genome_assembly=genome_assembly)).index\n",
    "            df_final.loc[match, idx] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(db_out_fname, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
